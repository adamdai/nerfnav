{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import pymesh\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = pymesh.load_mesh(\"data/3dmodels/landscape_example.obj\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot point cloud\n",
    "fig = go.Figure(data=[go.Scatter3d(\n",
    "    x=mesh.vertices[:, 0],\n",
    "    y=mesh.vertices[:, 1],\n",
    "    z=mesh.vertices[:, 2],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=2,\n",
    "        color=mesh.vertices[:, 2],                # set color to an array/list of desired values\n",
    "        colorscale='Viridis',   # choose a colorscale\n",
    "        opacity=0.8\n",
    "    )\n",
    ")])\n",
    "fig.update_layout(width=1600, height=900)\n",
    "fig.update_layout(scene = dict(aspectmode='data'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot mesh\n",
    "fig = go.Figure(data=[go.Mesh3d(x=mesh.vertices[:,0],\n",
    "                                y=mesh.vertices[:,1],\n",
    "                                z=mesh.vertices[:,2],\n",
    "                                i=mesh.faces[:,0],\n",
    "                                j=mesh.faces[:,1],\n",
    "                                k=mesh.faces[:,2],\n",
    "                                color='lightpink',\n",
    "                                opacity=0.50)])\n",
    "# Set figsize\n",
    "fig.update_layout(width=1600, height=900)\n",
    "fig.update_layout(scene = dict(aspectmode='data'))\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural elevation map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simpler simulated map\n",
    "X, Y = torch.meshgrid(torch.linspace(-1, 1, 100), torch.linspace(-1, 1, 100))\n",
    "X = X.reshape(-1, 1)\n",
    "Y = Y.reshape(-1, 1)\n",
    "z = torch.sin(2 * X) + torch.cos(2 * Y)\n",
    "xy = torch.cat((X, Y), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot \n",
    "fig = go.Figure(data=[go.Scatter3d(\n",
    "    x=X.reshape(-1),\n",
    "    y=Y.reshape(-1),\n",
    "    z=z.reshape(-1),\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=2,\n",
    "        color=z.reshape(-1),                # set color to an array/list of desired values\n",
    "        colorscale='Viridis',   # choose a colorscale\n",
    "        opacity=0.8\n",
    "    )\n",
    ")])\n",
    "fig.update_layout(width=1600, height=900)\n",
    "fig.update_layout(scene = dict(aspectmode='data'))\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full mesh               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = mesh.vertices[:,0]\n",
    "# Y = mesh.vertices[:,1]\n",
    "# Z = mesh.vertices[:,2]\n",
    "\n",
    "# x = torch.tensor(X, dtype=torch.float32)\n",
    "# y = torch.tensor(Y, dtype=torch.float32)\n",
    "# z = torch.tensor(Z, dtype=torch.float32)\n",
    "\n",
    "# xy = torch.stack([x, y], dim=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partial mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(mesh.vertices[:,0]), min(mesh.vertices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sine(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, input):\n",
    "        # See paper sec. 3.2, final paragraph, and supplement Sec. 1.5 for discussion of factor 30\n",
    "        return torch.sin(30 * input)\n",
    "    \n",
    "\n",
    "class SineLayer(nn.Module):\n",
    "    # See paper sec. 3.2, final paragraph, and supplement Sec. 1.5 for discussion of omega_0.\n",
    "    \n",
    "    # If is_first=True, omega_0 is a frequency factor which simply multiplies the activations before the \n",
    "    # nonlinearity. Different signals may require different omega_0 in the first layer - this is a \n",
    "    # hyperparameter.\n",
    "    \n",
    "    # If is_first=False, then the weights will be divided by omega_0 so as to keep the magnitude of \n",
    "    # activations constant, but boost gradients to the weight matrix (see supplement Sec. 1.5)\n",
    "    \n",
    "    def __init__(self, in_features, out_features, bias=True,\n",
    "                 is_first=False, omega_0=30):\n",
    "        super().__init__()\n",
    "        self.omega_0 = omega_0\n",
    "        self.is_first = is_first\n",
    "        \n",
    "        self.in_features = in_features\n",
    "        self.linear = nn.Linear(in_features, out_features, bias=bias)\n",
    "        \n",
    "        self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            if self.is_first:\n",
    "                self.linear.weight.uniform_(-1 / self.in_features, \n",
    "                                             1 / self.in_features)      \n",
    "            else:\n",
    "                self.linear.weight.uniform_(-np.sqrt(6 / self.in_features) / self.omega_0, \n",
    "                                             np.sqrt(6 / self.in_features) / self.omega_0)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        return torch.sin(self.omega_0 * self.linear(input))\n",
    "    \n",
    "\n",
    "class Siren(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, hidden_layers, out_features, outermost_linear=False, \n",
    "                 first_omega_0=30, hidden_omega_0=30.):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.net = []\n",
    "        self.net.append(SineLayer(in_features, hidden_features, \n",
    "                                  is_first=True, omega_0=first_omega_0))\n",
    "\n",
    "        for i in range(hidden_layers):\n",
    "            self.net.append(SineLayer(hidden_features, hidden_features, \n",
    "                                      is_first=False, omega_0=hidden_omega_0))\n",
    "\n",
    "        if outermost_linear:\n",
    "            final_linear = nn.Linear(hidden_features, out_features)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                final_linear.weight.uniform_(-np.sqrt(6 / hidden_features) / hidden_omega_0, \n",
    "                                              np.sqrt(6 / hidden_features) / hidden_omega_0)\n",
    "                \n",
    "            self.net.append(final_linear)\n",
    "        else:\n",
    "            self.net.append(SineLayer(hidden_features, out_features, \n",
    "                                      is_first=False, omega_0=hidden_omega_0))\n",
    "        \n",
    "        self.net = nn.Sequential(*self.net)\n",
    "    \n",
    "    def forward(self, coords):\n",
    "        coords = coords.clone().detach().requires_grad_(True) # allows to take derivative w.r.t. input\n",
    "        output = self.net(coords)\n",
    "        return output, coords      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "class DNN(torch.nn.Module):\n",
    "    \"\"\"Deep neural network.\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, layers):\n",
    "        \"\"\"Initialize the network.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        layers : list of int\n",
    "            List of layer dimensions.\n",
    "\n",
    "        \"\"\"\n",
    "        super(DNN, self).__init__()\n",
    "        \n",
    "        # parameters\n",
    "        self.depth = len(layers) - 1\n",
    "        \n",
    "        # set up layer order dict\n",
    "        #self.activation = torch.nn.ReLU\n",
    "        self.activation = torch.nn.Tanh\n",
    "        #self.activation = Sine\n",
    "        \n",
    "        layer_list = list()\n",
    "        for i in range(self.depth - 1): \n",
    "            layer_list.append(\n",
    "                ('layer_%d' % i, torch.nn.Linear(layers[i], layers[i+1]))\n",
    "            )\n",
    "            layer_list.append(('activation_%d' % i, self.activation()))\n",
    "            \n",
    "        layer_list.append(\n",
    "            ('layer_%d' % (self.depth - 1), torch.nn.Linear(layers[-2], layers[-1]))\n",
    "        )\n",
    "        layerDict = OrderedDict(layer_list)\n",
    "        \n",
    "        # deploy layers\n",
    "        self.layers = torch.nn.Sequential(layerDict)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\" Forward pass. \"\"\"\n",
    "        out = self.layers(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural net to predict z from (x,y)\n",
    "# TODO: try different activation functions\n",
    "#  - tanh\n",
    "#  - sine\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, n_feature, n_hidden, n_output):\n",
    "        super(Net, self).__init__()\n",
    "        self.hidden = nn.Linear(n_feature, n_hidden)   # hidden layer\n",
    "        self.predict = nn.Linear(n_hidden, n_output)   # output layer\n",
    "        self.activation = F.relu\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.hidden(x))      # activation function for hidden layer\n",
    "        x = self.predict(x)             # linear output\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#net = Net(n_feature=2, n_hidden=10, n_output=1)\n",
    "#net = DNN([2, 100, 100, 1])\n",
    "net = Siren(in_features=2, out_features=1, hidden_features=256, hidden_layers=3, outermost_linear=True)\n",
    "\n",
    "#optimizer = torch.optim.SGD(net.parameters(), lr=0.05)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-4)\n",
    "loss_fn = torch.nn.MSELoss()  # this is for regression mean squared loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Siren weight initialization\n",
    "# # For each layer, draw weights from U(-sqrt(6/n), sqrt(6/n)) where n is input dimension to layer\n",
    "\n",
    "# for layer in net.layers:\n",
    "#     if isinstance(layer, nn.Linear):\n",
    "#         w = layer.weight.data\n",
    "#         n = w.shape[1]\n",
    "#         layer.weight.data = (2 * torch.rand(w.shape) - 1) * torch.sqrt(torch.tensor(6 / n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 1000\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # Forward pass: Compute predicted y by passing x to the model\n",
    "    \n",
    "    z_pred, coords = net(xy)\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = loss_fn(z_pred, z)\n",
    "    if epoch % 100 == 0:\n",
    "        print('epoch: ', epoch,' loss: ', loss.item())\n",
    "\n",
    "    # Zero gradients, perform a backward pass, and update the weights.\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot NN prediction\n",
    "fig = go.Figure(data=[go.Scatter3d(\n",
    "    x=X.reshape(-1),\n",
    "    y=Y.reshape(-1),\n",
    "    z=z_pred.detach().numpy().reshape(-1),\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=2,\n",
    "        color=z_pred.detach().numpy().reshape(-1),                # set color to an array/list of desired values\n",
    "        colorscale='Viridis',   # choose a colorscale\n",
    "        opacity=0.8\n",
    "    )\n",
    ")])\n",
    "fig.update_layout(width=1600, height=900)\n",
    "fig.update_layout(scene = dict(aspectmode='data'))\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nerf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
